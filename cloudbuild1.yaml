# - Airflow Env variables.
substitutions:
  _COMPOSER_REGION: asia-south1
  _COMPOSER_ENV_NAME: arflow-hasim

# Access the id_github file from Secret Manager, and setup SSH
steps:
  - name: 'gcr.io/cloud-builders/git'
    secretEnv: ['SSH_KEY']
    entrypoint: 'bash'
    args:
    - -c
    - |
      echo "$$SSH_KEY" >> /root/.ssh/id_rsa
      chmod 400 /root/.ssh/id_rsa
      ssh-keyscan -t rsa github.com > known_hosts.github
      cp known_hosts.github /root/.ssh/known_hosts
# cat known_hosts.github
    volumes:
    - name: 'ssh'
      path: /root/.ssh

# Clone the repository
  - name: 'gcr.io/cloud-builders/git'
    args:
    - clone
    - --recurse-submodules
    - git@github.com:Hasimk/cicd-sample.git
    volumes:
    - name: 'ssh'
      path: /root/.ssh

# install dependencies
  - name: python:3.10
    entrypoint: pip
    args: ["install", "-r", "requirements.txt", "-c", "constraints.txt", "--user"]

  - name: python:3.10
    entrypoint: pip
    args: ["install", "-r", "requirements-test.txt", "--user"]

  # run in python 3.8 which is latest version in Cloud Composer
  - name: python:3.10
    entrypoint: python3.8
    args: ["-m", "pytest", "-s", "dags/"]

  # import to cloud composer
  - name: 'gcr.io/cloud-builders/gcloud'
    entrypoint: 'bash'
    args:
    - '-c'
    - |
      for dagfile in $(ls dags)
        do
        gcloud composer environments storage dags import \
        --environment $_COMPOSER_ENV_NAME \
        --location $_COMPOSER_REGION \
        --source dags/$$dagfile
        done
 # [Start Artifact registry]
  - name: 'gcr.io/cloud-builders/docker'
    args: [ 'build', '-t', '$_COMPOSER_REGION-docker.pkg.dev/$PROJECT_ID/hasim-airflow/quickstart-image:tag6', '.' ]

  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', '$_COMPOSER_REGION-docker.pkg.dev/$PROJECT_ID/hasim-airflow/quickstart-image:tag6']

availableSecrets:
    secretManager:
    - versionName: projects/591981386330/secrets/SSH_KEY/versions/latest
      env: 'SSH_KEY'
